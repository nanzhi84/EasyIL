seed: 42

algo:
  name: sqil

  # SAC-style policy
  actor_lr: 3e-4
  critic_lr: 3e-4
  gamma: 0.99
  tau: 0.005
  alpha: 0.2
  auto_alpha: true
  grad_clip: 1.0

  # SQIL specific
  expert_reward: 1.0
  policy_reward: 0.0

  actor:
    hidden: 256
    depth: 2
    log_std_min: -20.0
    log_std_max: 2.0
    action_clip: 1.0

  critic:
    hidden: 256
    depth: 2

train:
  mode: online

  expert_data:
    path: data/HalfCheetah-v5/expert_data/trajs.npz
    obs_normalize: true
    num_trajs: 10

  sampler:
    type: balanced
    expert_ratio: 0.5

  total_timesteps: 1000000
  batch_size: 256
  buffer_size: 1000000

  update_after: 10000
  update_every: 50
  collect_per_step: 1

  log_freq: 1000
  eval_freq: 10000
  n_eval_episodes: 10
  final_eval_episodes: 10

  save_best: true
  checkpoint_freq: 100000
  progress_bar: true
  device: auto

env:
  id: HalfCheetah-v5
  kwargs: {}

  reward:
    model_path: null

logger:
  enabled: false
  type: null

hydra:
  run:
    dir: outputs/${env.id}/${algo.name}/${now:%Y-%m-%d}/${now:%H-%M-%S}
  sweep:
    dir: multirun/${env.id}/${algo.name}/${now:%Y-%m-%d}/${now:%H-%M-%S}
    subdir: ${hydra.job.num}
